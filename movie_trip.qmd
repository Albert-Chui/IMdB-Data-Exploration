---
title: "Mini Project 2"
author: 
  - Albert Chui (albertchui)
  - Joseph Zaki (josephzaki)
date: "May 12, 2024"
format: pdf
fontsize: 12pt
number-sections: TRUE
linkcolor: purple
geometry:
  - margin=1in
toc: TRUE
---
# Abstract {#sec-abstract}

\begin{abstract}
In this paper we explore data from the official IMdB database detailing 998998 movies and 357879 TV Series. We find that the average rating between genres varies between significantly when testing Documentary vs Action and Crime vs Sports and that ratings did not vary significantly between News and Drama. We also performed ANOVA tests for groups of genres (Romance, Sci-Fi, Western, War and Fantasy, Comedy, Horror). We found that mean ratings varied significantly according to genre in these groups. Additionally, we performed tests for changes in mean ratings within genres across years and found that there was a significant difference in mean ratings across the years within the genres of History, Animation, and Shorts. We also performed an analysis of runtimes for movies and TV Series, we found that mean movie runtime prior to 1950 varied greatly, but stabilized after to between 90 and 100 minutes. Similarly, mean TV series run time varied greatly before 1975, after which they began stabilizing around 50 minutes. For both movies we performed an ANOVA test and found that movie runtimes varied significantly between years, whereas for TV series we performed a two sample test to determine if there is a significant in runtimes for TV series beginning before 1975 and those beginning after 1975. We did not find a significant difference between these two groups. Finally, we attempted to determine if the runtime of a movie had an effect on its mean rating. By plotting the ratings of movies against their runtime, we observed a positive association between the variables. This led us to conduct a hypothesis test to determine if movies longer than 150 minutes received higher ratings than those shorter than 150 minutes. After conducting this test, we found that movies longer than 150 minutes did receive significantly higher ratings than those shorter than 150 minutes.
\end{abstract}


```{r, echo = F, message = F}
library("tidyverse")
library("pander")
```


```{r, echo = F}
basics <- read.csv("data/basics.csv") 
ratings <- read.csv("data/ratings.csv")
```

```{r, echo = F}
basics <- basics %>%
  mutate(genres = strsplit(as.character(genres), ",")) %>%
  unnest(genres)

movies <- left_join(
  basics, 
  ratings, 
  by = join_by(tconst == tconst)
)
```
# Dataset Examination
Let us first look at all of our unique genres in this dataset:

```{r, echo = F}
# Romance , Documentary, Mystery, Talk, Short, Animation
genre_ratings <- movies %>%
  group_by(genres) %>%
  summarise(avg_rating = mean(averageRating, na.rm = T), num_movies = n())
genre_ratings <- genre_ratings[order(genre_ratings$avg_rating, decreasing=T),]
genre_ratings %>% filter(genres != "\\N") %>% pander()
```

# Testing for Differences in Mean Rating Across Genres

In this section we will perform several hypothesis tests on different genres to determine if there is a difference in the mean rating based on genre.

## Documentary vs Action

Here, we specifically test for a difference in mean rating between documentaries and action programs. To do this, we test the following hypotheses:
$$
\begin{cases}
H_0:\mu_{documentary} = \mu_{action}\\
H_a:\mu_{documentary} \ne \mu_{action}\\
\end{cases}
$$
```{r, warning=F, echo=F}
documentary_ratings <- movies %>% filter(`genres` == "Documentary") %>% pull(`averageRating`)
action_ratings <- movies %>% filter(`genres` == "Action") %>% pull(`averageRating`)

t.test(x = documentary_ratings,
       y = action_ratings,
       alternative = 'two.sided',
       conf.level = 0.95,
       na.rm = T)

movies %>%
  filter(genres == "Action" | genres == "Documentary") %>%
  ggplot(aes(x = genres, y = averageRating)) +
  geom_boxplot(staplewidth = 0.25) +
  labs(x = "Genre", y = "Average Rating", title = "Documentary vs. Action") +
  theme_bw()
```
From the results of our two-sample t-test we can see that our p-value is smaller than 0.05, which means there is a significant difference in mean ratings across Documentaries and Action movies/series. From the boxplot, we can see that the mean rating for both categories seems to clearly differ.

## Crime vs Sports

Here, we specifically test for a difference in mean rating between crime and sports programs. To do this we test the following hypotheses:
$$
\begin{cases}
H_0:\mu_{crime} = \mu_{sports}\\
H_a:\mu_{crime} \ne \mu_{sports}\\
\end{cases}
$$
```{r, warning=F, echo=F}
crime_ratings <- movies %>% filter(`genres` == "Crime") %>% pull(`averageRating`)
sport_ratings <- movies %>% filter(`genres` == "Sport") %>% pull(`averageRating`)

t.test(x = crime_ratings,
       y = sport_ratings,
       alternative = 'two.sided',
       conf.level = 0.95,
       na.rm = T)

movies %>%
  filter(genres == "Crime" | genres == "Sport") %>%
  ggplot(aes(x = genres, y = averageRating)) +
  geom_boxplot(staplewidth = 0.25) +
  labs(x = "Genre", y = "Average Rating", title = "Crime vs. Sport") +
  theme_bw()
```
From the results of our two-sample t-test we can see that our p-value is smaller than 0.05, which means there is a significant difference in mean ratings across Crime and Sports movies/series. From the boxplot, we can see that the mean rating for both categories differs slightly, but only through our t-test can we tell that this is a significant differnece.

## News vs Drama

Here, we specifically test for a difference in mean rating between News and Drama programs. To do this we test the following hypotheses:
$$
\begin{cases}
H_0:\mu_{news} = \mu_{drama}\\
H_a:\mu_{news} \ne \mu_{drama}\\
\end{cases}
$$
```{r, warning=F, echo=F}
news_ratings <- movies %>% filter(`genres` == "News") %>% pull(`averageRating`)
drama_ratings <- movies %>% filter(`genres` == "Drama") %>% pull(`averageRating`)

t.test(x = news_ratings,
       y = drama_ratings,
       alternative = 'two.sided',
       conf.level = 0.95,
       na.rm = T)

movies %>%
  filter(genres == "News" | genres == "Drama") %>%
  ggplot(aes(x = genres, y = averageRating)) +
  geom_boxplot(staplewidth = 0.25) +
  labs(x = "Genre", y = "Average Rating", title = "Drama vs. News") +
  theme_bw()
```
From the results of our two-sample t-test we can see that our p-value is larger than 0.05, which means there is not a significant difference in mean ratings across Crime and Sports movies/series. From the boxplot, we can see that the mean rating for both categories is very similar, appearing almost identical.


## Romance vs Sci-Fi vs War vs Western

In this section we test for differences in mean ratings across groups larger than 2 genres, meaning we need to perform an Analysis of Variance test.

### Check Assumptions

1) **Normality**
```{r, echo=F}
scifi_ratings <- movies %>% filter(`genres` == "Sci-Fi") %>% pull(`averageRating`)
war_ratings <- movies %>% filter(`genres` == "War") %>% pull(`averageRating`)
romance_ratings <- movies %>% filter(`genres` == "Romance") %>% pull(`averageRating`)
western_ratings <- movies %>% filter(`genres` == "Western") %>% pull(`averageRating`)

qqnorm(scifi_ratings, main = "Sci-Fi Normal Q-Q Plot")
qqnorm(war_ratings, main = "War Normal Q-Q Plot")
qqnorm(romance_ratings, main = "Romance Normal Q-Q Plot")
qqnorm(western_ratings, main = "Western Normal Q-Q Plot")
```
From the above Q-Q Plots, we can see that our normality assumption holds for all four genres.

2) Homoscedasticity (Constant Variance)

```{r, echo  = F}
movies %>% filter(genres %in% c("Romance", "Western", "War", "Sci-Fi")) %>% select(genres, averageRating) %>% na.omit() %>%
  ggplot(aes(x = genres, y = averageRating)) +
  geom_boxplot(staplewidth = 0.25)
```
From the above boxplots, we can see that the assumption of Homoscedasticity holds for this dataset as all four genres seem to have approximately the same variance.

3) Independence

Although we cannot test for independence, it is unlikely that the ratings for one movie or series strongly effects the rating for a different movie or series, meaning our assumption of Independence is most likely not violated.

### Conduct ANOVA Test

$$
\begin{cases}
H_0: \mu_{war} = \mu_{romance} = \mu_{western} = \mu_{sci-fi}\\
H_a: \text{At least one mean differs from the others}
\end{cases}
$$
```{r, echo = F}
aov_df <- movies %>% filter(genres %in% c("Romance", "Western", "War", "Sci-Fi")) %>% select(genres, averageRating) %>% na.omit()
aov(averageRating ~ genres, data = aov_df) %>% summary()
```
From the results of our ANOVA test above, we can see that our p-value is very small, much smaller than 0.05, meaning we can reject $H_0: \mu_{war} = \mu_{romance} = \mu_{western} = \mu_{sci-fi}$, indicating there is a significant difference in the mean ratings for at least one of the tested genres (Romance, War, Western, Sci-Fi).


## Fantasy vs Comedy vs Horror

In this section we test for differences in mean ratings across groups larger than 2 genres, meaning we need to perform an Analysis of Variance test.

### Check Assumptions

1) **Normality**
```{r, echo=F}
fantasy_ratings <- movies %>% filter(`genres` == "Fantasy") %>% pull(`averageRating`)
comedy_ratings <- movies %>% filter(`genres` == "Comedy") %>% pull(`averageRating`)
horror_ratings <- movies %>% filter(`genres` == "Horror") %>% pull(`averageRating`)

qqnorm(fantasy_ratings, main = "Fantasy Normal Q-Q Plot")
qqnorm(comedy_ratings, main = "Comedy Normal Q-Q Plot")
qqnorm(horror_ratings, main = "Horror Normal Q-Q Plot")
```
From the above Q-Q Plots, we can see that our normality assumption holds for all three genres.

2) Homoscedasticity (Constant Variance)

```{r, echo  = F}
movies %>% filter(genres %in% c("Fantasy", "Comedy", "Horror")) %>% select(genres, averageRating) %>% na.omit() %>%
  ggplot(aes(x = genres, y = averageRating)) +
  geom_boxplot(staplewidth = 0.25)
```
From the above boxplots, we can see that the assumption of Homoscedasticity holds for this dataset as all three genres seem to have approximately the same variance.

3) Independence

Although we cannot test for independence, it is unlikely that the ratings for one movie or series strongly effects the rating for a different movie or series, meaning our assumption of Independence is most likely not violated.

### Conduct ANOVA Test

$$
\begin{cases}
H_0: \mu_{fantasy} = \mu_{comedy} = \mu_{horror}\\
H_a: \text{At least one mean differs from the others}
\end{cases}
$$
```{r, echo = F}
aov_df <- movies %>% filter(genres %in% c("Fantasy", "Comedy", "Horror")) %>% select(genres, averageRating) %>% na.omit()
aov(averageRating ~ genres, data = aov_df) %>% summary()
```
From the results of our ANOVA test above, we can see that our p-value is very small, much smaller than 0.05, meaning we can reject $H_0: \mu_{fantasy} = \mu_{comedy} = \mu_{horror}$, indicating there is a significant difference in the mean ratings for at least one of the tested genres (Fantasy, Comedy, Horror).


# Testing for Differences in Mean Ratings Within Genres Across Years

In this section we investigate if there are significant changes to the mean ratings of several genres across different years. We focus on the genres of History, Short Films, and Animation.

```{r, echo=F, fig.width=8, message = F}
within_generes_df <- movies %>% filter(genres %in% c("Short", "History", "Animation")) %>% select(genres, startYear, averageRating) %>% na.omit()

within_generes_df %>%
  group_by(genres, startYear) %>%
  summarise(meanRating = mean(averageRating)) %>%
  ggplot(aes(x = startYear, y = meanRating, group = 1)) +
  geom_line()+
  facet_wrap("genres") +
  scale_x_discrete(breaks = seq(0, max(within_generes_df$startYear), by = 25)) +
  labs(x = "Year", y = "Mean Rating", title = "Mean Rating over Time by Genre") +
  theme_bw()
```

From the above graph displaying mean ratings in each year by genre, we can already see that the mean rating within each genre seems to vary greatly each year and tends to oscillate especially before 1950. In order to statistically test for difference in mean rating across years, we conducted an ANOVA test for each genre.

# Conduct ANOVA Test for Shorts, History, and Animation Mean Ratings Across Years

## Check Assumptions

Since we have tested the assumption of Normality, Homoscedasticity, and Independence for other genres and found that they hold, it is reasonable to assume that they hold for these genres as well since all the data is coming from the same source.

## Conduct ANOVA Test

$$
\begin{cases}
H_0: \mu_{i} = \mu_{j} ; \text{for } i,j \in \text{Years and } i\ne j \\
H_a: \text{At least one mean differs from the others}
\end{cases}
$$
```{r, echo = F}
aov_df <- movies %>% 
  filter(genres == "Short") %>% 
  select(startYear, averageRating) %>% 
  na.omit() #%>%
  #group_by(startYear) %>% 
  #summarise(mean_rating = mean(averageRating))

within_generes_df <- movies %>% filter(genres %in% c("Short", "History", "Animation")) %>% select(genres, startYear, averageRating) %>% na.omit()

aov(averageRating ~ startYear, data = within_generes_df) %>% summary()
```
From the results of our ANOVA test above, we can see that our p-value is very small, much smaller than 0.05, meaning we can reject 
$H_0: \mu_{i} = \mu_{j} ; \text{for } i,j \in \text{Years and } i\ne j$, indicating there is a significant difference in the mean ratings within genres across years for the tested genres (Shorts, Animation, and History).


# Testing for differences between Runtime and Years for Movies and TV series

## Movies
```{r, echo = F, warning = F}
movies$runtimeMinutes <- as.numeric(movies$runtimeMinutes)
timed_runlength <- movies %>%
  group_by(startYear) %>%
  filter(titleType == "movie") %>%
  summarise(avg_runtime = mean(runtimeMinutes, na.rm = T))
```

```{r, echo = F, warning = F}
ggplot(timed_runlength)+
  geom_line(aes(x=`startYear`, y = `avg_runtime`), group = 1) + 
  labs(x = "Year", y = "Average Runtime in Minutes", title = "Average Runtime of Movies Through the Years") +
  scale_x_discrete(breaks = seq(0, max(timed_runlength$startYear), by = 25))
```
Visually, it seems that average movie length have not varied much year to year after to 1950. Prior to 1950, mean length varied greatly year to year. They have remained constant after 1950 at run times of 90 to 100 minutes. We can see that the mean run time in 2024 appears very low, this could be caused by the fact that the year is not over and many movies have not yet been released.

### Conduct ANOVA Test For Mean Runtime of Movies

$$
\begin{cases}
H_0: \mu_{i} = \mu_{j} ; \text{for } i,j \in \text{Years and } i\ne j \\
H_a: \text{At least one mean differs from the others}
\end{cases}
$$

```{r, echo = F}
movies$runtimeMinutes <- as.numeric(movies$runtimeMinutes)

runtime_df <- movies %>% filter(runtimeMinutes > 0 & titleType == "movie") %>% 
  select(startYear, runtimeMinutes) %>% na.omit() 
#%>% group_by(startYear) %>% summarise(runtimeMinutes = mean(runtimeMinutes))


aov(runtimeMinutes ~ startYear, data = runtime_df) %>% summary()
```
From the ANOVA Test results, we find a p-value much lower than 0.05, meaning we can reject $H_0: \mu_{i} = \mu_{j} ; \text{for } i,j \in \text{Years and } i\ne j$ indicating that the runtimes of movies do change significantly year to year. 

## TV Series
```{r, echo = F}
movies$runtimeMinutes <- as.numeric(movies$runtimeMinutes)

series_timed_runlength <- movies %>%
  group_by(startYear) %>%
  filter(titleType == "tvSeries") %>%
  summarise(avg_runtime = mean(runtimeMinutes, na.rm = T))
```

```{r, echo=F}
ggplot(series_timed_runlength)+
  geom_line(aes(x=`startYear`, y = `avg_runtime`), group = 1) + 
  labs(x = "Year", y = "Average Runtime", title = "Average Runtime of TV Series Through the Years") +
  scale_x_discrete(breaks = seq(0, max(series_timed_runlength$startYear), by = 25)) +
  ylim(0, 60)
```
From the plot, we can see that prior to 1950, mean episode runtime varied greatly year to year. They have stabilized after 1950 at runtimes of around 50 minutes. We can see that the mean run time in 2024 appears very low, this could be caused by the fact that the year is not over and many TV Series have not yet been released. Overall, it does appear that the average runtime of TV Series has increased since 1920-1975 up to about 50 minutes where runtimes have stabilized.

### Conduct ANOVA Test for Mean Runtime of TV Series

$$
\begin{cases}
H_0: \mu_{\text{before 1975}} = \mu_{\text{after 1975}}\\
H_a: \mu_{\text{before 1975}} < \mu_{\text{after 1975}}
\end{cases}
$$

```{r, echo = F}
before_1975_runtimes <- series_timed_runlength %>% na.omit() %>% filter(startYear <= 1975) %>% pull(avg_runtime)
after_1975_runtimes <- series_timed_runlength %>% na.omit() %>% filter(startYear > 1975) %>% pull(avg_runtime)

t.test(x = before_1975_runtimes,
       y = after_1975_runtimes,
       alternative = 'less',
       conf.level = 0.95)
```
By performing a two-sample t-test on the average runtimes of TV Series before 1975 vs after 1975, we find a p-value of 0.8555. This means we fail to reject $H_0: \mu_{\text{before 1975}} = \mu_{\text{after 1975}}$, meaning we did not find a significant difference in mean runtime of TV Series in the years before 1975 and after 1975. This means TV Series runtimes have not gotten significantly longer over time.

# Does the Runtime of a Movie affect it's Rating?

```{r, echo=F, warning=F}
runtime_ratings <- movies %>% filter(titleType == "movie", runtimeMinutes < 300) %>% select(startYear, averageRating, runtimeMinutes)

runtime_ratings %>%
  ggplot(aes(x = runtimeMinutes, y = averageRating)) +
  geom_point(size = 0.5) + 
  theme_bw() +
  labs(x = "Runtime in Minutes", y = "Average Rating", title = "Average Rating vs Runtime (mins)")
```
From the above scatterplot, we can see that beyond 150 minutes of runtime, an increase in runtime is associated with an increase in the average rating of a film.

To test this we can perform a two sample t-test on the following hypotheses to test if there is a significant difference in mean rating between movies with runtimes less than 150 minutes and movies with runtimes of more than 150 minutes.

$$
\begin{cases}
H_0: \mu_{\text{less than 150 minutes}} = \mu_{\text{greater than 150 minutes}}\\
H_a: \mu_{\text{less than 150 minutes}} < \mu_{\text{greater than 150 minutes}}
\end{cases}
$$
```{r, echo=F}
runtime_ratings_morethan2 <- movies %>% filter(titleType == "movie", runtimeMinutes > 150) %>% select(startYear, averageRating, runtimeMinutes) %>% pull(averageRating) %>% na.omit()

runtime_ratings_lessthan2 <- movies %>% filter(titleType == "movie", runtimeMinutes < 150) %>% select(startYear, averageRating, runtimeMinutes) %>% pull(averageRating) %>% na.omit()

t.test(x =  runtime_ratings_lessthan2,
       y = runtime_ratings_morethan2,
       alternative = "less",
       conf.level = 0.95)
```
Through our hypothesis test, we find a p-value smaller than 0.05, meaning we can reject $H_0: \mu_{\text{less than 150 minutes}} = \mu_{\text{greater than 150 minutes}}$, indicating that the average rating of films longer than 150 minutes is significantly greater than the average rating of films less than 150 minutes.
